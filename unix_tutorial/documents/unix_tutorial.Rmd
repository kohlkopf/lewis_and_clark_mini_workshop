---
title: "Tutorial: Unix navigation"
subtitle: "L&C College Bioinfo workshop"
author: "Kohl Kinning"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    theme: cosmo
    toc: yes
    toc_float:
      collapsed: yes
editor_options: 
  chunk_output_type: inline
---

# Intro to shell
## What is a shell and why should I care?

A shell is a computer program that presents a command line interface which allows you to control your computer using commands entered with a keyboard instead of controlling graphical user interfaces (GUIs) with a mouse/keyboard combination.

There are many reasons to learn about the shell.

+ Many bioinformatics tools can only be used through a command line interface, or have extra capabilities in the command line version that are not available in the GUI. This is true, for example, of BLAST, which offers many advanced functions only accessible to users who know how to use a shell.
+ The shell makes your work less boring. In bioinformatics you often need to do the same set of tasks with a large number of files. Learning the shell will allow you to automate those repetitive tasks and leave you free to do more exciting things.
+ The shell makes your work less error-prone. When humans do the same thing a hundred different times (or even ten times), they’re likely to make a mistake. Your computer can do the same thing a thousand times with no mistakes.
+ The shell makes your work more reproducible. When you carry out your work in the command-line (rather than a GUI), your computer keeps a record of every step that you’ve carried out, which you can use to re-do your work when you need to. It also gives you a way to communicate unambiguously what you’ve done, so that others can check your work or apply your process to new data.
+ Many bioinformatic tasks require large amounts of computing power and can’t realistically be run on your own machine. These tasks are best performed using remote computers or cloud computing, which can only be accessed through a shell.

In this lesson you will learn how to use the command line interface to move around in your file system.

## How to access the shell
On a Mac or Linux machine, you can access a shell through a program called Terminal, which is already available on your computer. If you’re using Windows, you can download a separate program to access the shell. 

We are currently connected to RStudio Cloud, which is running on a remote cluster somewhere else (likely) in the US. This server is running Linux. To avoid downloading files to personal computer and dealing with inconsistent envrionments, we'll navigate our file structure on the linux machine that is running RStudio Cloud.

Expand the **Console** pane. There should be four tabs, *Console*, *Terminal*, *RMarkdown*, and *Jobs*. Choose *Terminal*. This is nearly identical to the terminal that you might access on your own computer. To run the commands, type them directly in to the terminal prompt. 

## Navigating your file system
The part of the operating system responsible for managing files and directories is called the file system. It organizes our data into files, which hold information, and directories (also called “folders”), which hold files or other directories.

Several commands are frequently used to create, inspect, rename, and delete files and directories.

Let’s find out where we are by running a command called `pwd` (which stands for “print working directory”). At any moment, our current working directory is our current default directory, i.e., the directory that the computer assumes we want to run commands in unless we explicitly specify something else. Here, the computer’s response is cloud/project/lewis_and_clark_mini_workshop/unix_tutorial, which is the top level directory within our cloud system:

```bash
$ pwd
```
```
/projects/cloud
```
Let’s look at how our file system is organized.

At the top is our dcuser directory, which holds all the subdirectories and files.

Inside that directory are some other directories:

```bash
$ ls
```
```
project.RProj    software    documents    untrimmed_fastq
```
We’ll be working with these subdirectories throughout this workshop.

The command to change locations in our file system is cd followed by a directory name to change our working directory. cd stands for “change directory”.

Let’s say we want to navigate to the data directory we saw above. We can use the following command to get there:

```bash
$ cd data
```
We can see files and subdirectories are in this directory by running ls, which stands for “listing”:

```bash
$ ls
```
```
sra_metadata  untrimmed_fastq
```
ls prints the names of the files and directories in the current directory in alphabetical order, arranged neatly into columns. We can make its output more comprehensible by using the flag -F, which tells ls to add a trailing / to the names of directories:

```bash
$ ls -F
```
```
sra_metadata/  untrimmed_fastq/
```
Anything with a “/” after it is a directory. Things with a “*” after them are programs. If there are no decorations, it’s a file.

ls has lots of other options. To find out what they are, we can type:

```bash
$ man ls
```
Some manual files are very long. You can scroll through the file using your keyboard’s down arrow or use the Space key to go forward one page and the b key to go backwards one page. When you are done reading, hit q to quit.

Let’s go into the untrimmed_fastq directory and see what is in there.

```bahs
$ cd untrimmed_fastq
$ ls -F
```
```
SRR097977.fastq  SRR098026.fastq
```
This directory contains two files with .fastq extensions. FASTQ is a format for storing information about sequencing reads and their quality. We will be learning more about FASTQ files in a later lesson.

## Shortcut: Tab Completion
Typing out file or directory names can waste a lot of time and it’s easy to make typing mistakes. Instead we can use tab complete as a shortcut. When you start typing out the name of a directory or file, then hit the Tab key, the shell will try to fill in the rest of the directory or file name.

Return to your home directory:

```bash
$ cd cloud/project/lewis_and_clark_mini_workshop/unix_tutorial
```
then enter:

```bash
$ cd sam<tab>
```
The shell will fill in the rest of the directory name for data.

Now change directories to untrimmed_fastq in data

```bash
$ cd data
$ cd untrimmed_fastq
```
Using tab complete can be very helpful. However, it will only autocomplete a file or directory name if you’ve typed enough characters to provide a unique identifier for the file or directory you are trying to access.

If we navigate back to our untrimmed_fastq directory and try to access one of our sample files:
```bash
$ cd
$ cd data
$ cd untrimmed_fastq
$ ls SR<tab>
```
The shell auto-completes your command to SRR09, because all file names in the directory begin with this prefix. When you hit Tab again, the shell will list the possible choices.

```bash
$ ls SRR09<tab><tab>
```
```
SRR097977.fastq  SRR098026.fastq
```
Tab completion can also fill in the names of programs, which can be useful if you remember the begining of a program name.

```bash
$ pw<tab><tab>
```
```
pwd         pwd_mkdb    pwhich      pwhich5.16  pwhich5.18  pwpolicy
```
Displays the name of every program that starts with pw.

## Summary
We now know how to move around our file system using the command line. This gives us an advantage over interacting with the file system through a GUI as it allows us to work on a remote server, carry out the same set of operations on a large number of files quickly, and opens up many opportunities for using bioinformatics software that is only available in command line versions.






# Using programs

## Bioinformatics workflows

When working with high-throughput sequencing data, the raw reads you get off of the sequencer will need to pass through a number of  different tools in order to generate your final desired output. The execution of this set of tools in a specified order is commonly referred to as a *workflow* or a *pipeline*. 

An example of the workflow we will be using for our variant calling analysis is provided below with a brief description of each step. 

![](./media/variant_calling_workflow.png)


1. Quality control - Assessing quality using FastQC
2. Quality control - Trimming and/or filtering reads (if necessary)
3. Align reads to reference genome 
4. Perform post-alignment clean-up
5. Variant calling

These workflows in bioinformatics adopt a plug-and-play approach in that the output of one tool can be easily used as input to another tool without any extensive configuration. Having standards for data formats is what  makes this feasible. Standards ensure that data is stored in a way that is generally accepted and agreed upon  within the community. The tools that are used to analyze data at different stages of the workflow are therefore  built under the assumption that the data will be provided in a specific format.  


## Quality Control

The first step in the variant calling workflow is to take the FASTQ files received from the sequencing facility and assess the quality of the sequence reads. 

![](./media/var_calling_workflow_qc.png)
## Details on the FASTQ format

Although it looks complicated (and it is), it's easy to understand the [fastq](https://en.wikipedia.org/wiki/FASTQ_format) format with a little decoding. Some rules about the format include...

Fastq format:


1. Always begins with '@' and then information about the read
2. The actual DNA sequence
3. Always begins with a '+' and sometimes the same info in line 1
4. Has a string of characters which represent the quality scores; must have same number of characters as line 2

We can view the first complete read in one of the files our dataset by using `head` to look at the first four lines.

```bash
$ head -n4 SRR098026.fastq
```

```
@SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35
NNNNNNNNNNNNNNNNCNNNNNNNNNNNNNNNNNN
+SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35
!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!
```


All but one of the nucleotides in this read are unknown (`N`). This is a pretty bad read!

Line 4 shows the quality for each nucleotide in the read. Quality is interpreted as the  probability of an incorrect base call (e.g. 1 in 10) or, equivalently, the base call  accuracy (eg 90%). To make it possible to line up each individual nucleotide with its quality score, the numerical score is converted into a code where each individual character represents the numerical quality score for an individual nucleotide. For example, in the line above, the quality score line is: 

```
!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!
```


The `#` character and each of the `!` characters represent the encoded quality for an  individual nucleotide. The numerical value assigned to each of these characters depends on the  sequencing platform that generated the reads. The sequencing machine used to generate our data  uses the standard Sanger quality PHRED score encoding, using by Illumina version 1.8 onwards. Each character is assigned a quality score between 0 and 40 as shown in the chart below.

```
Quality encoding: !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHI
                  |         |         |         |         |
Quality score:    0........10........20........30........40                                
```


Each quality score represents the probability that the corresponding nucleotide call is incorrect. This quality score is logarithmically based, so a quality score of 10 reflects a quality score of 20 reflects a base call accuracy of 99%.  results from the base calling algorithm and dependent on how  much signal was captured for the base incorporation. 

Looking back at our read: 

```
@SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35
NNNNNNNNNNNNNNNNCNNNNNNNNNNNNNNNNNN
+SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35
!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!
```

we can now see that the quality of each of the `N`s is 0 and the quality of the only nucleotide call (`C`) is also very poor (`#` = a quality score of 2). This is indeed a very bad read. 


### Assessing Quality using FastQC

In real life, you won't be assessing the quality of your reads by visually inspecting yourFASTQ files. Rather, you'll be using a software program to assess read quality and  filter out poor quality reads. We'll first use a program called [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) to visualize the quality of our reads.  Later in our workflow, we'll use another program to filter out poor quality reads. 

FastQC has a number of features which can give you a  quick impression of any problems your issues into consideration before moving forward with your analyses. Rather than looking at quality scores for each individual read, FastQC looks at quality collectively across all reads within a sample. The image below shows a FastQC-generated plot that indicates a very high quality sample:

![](./media/good_quality1.8.png)

The x-axis displays the base position in the read, and the y-axis shows quality scores. In this example, the sample contains reads that are 40 bp long. For each position, there is a  box-and-whisker plot showing the distribution of quality scores for all reads at that position. The horizontal red line indicates the median quality score and the yellow box shows the 2nd to 3rd quartile range. This means that 50% of reads have a quality score that falls within the range of the yellow box at that position. The whiskers show the range to the 1st and 4th  quartile.

For each position in this sample, the quality values do not drop much lower than 32. This  is a high quality score. The plot background is also color-coded to identify good (green), acceptable (yellow), and bad (red) quality scores.

Now let's take a look at a quality plot on the other end of the spectrum. 

![](./media/bad_quality1.8.png)

Here, we see positions within the read in which the boxes span a much wider range. Also, quality scores drop quite low into the "bad" range, particularly on the tail end of the reads. The FastQC tool produces several other diagnostic plots to assess sample quality, in addition to the one plotted above. 

### Running FastQC  

We will be working with a set of sample data that is located in a hidden directory (`.dc_sampledata_lite`). First, we will move some of these hidden files to the `data` directory your created at [the end of our last lesson](http://www.datacarpentry.org/shell-genomics/06-organization/).  


Navigate to your FASTQ dataset: 

```bash
$ cd cloud/project/lewis_and_clark_mini_workshop/unix_tutorial/data/untrimmed_fastq/
```

To run the FastQC program, we need to tell our computer where the program is located  (in `~/FastQC`).  FastQC can accept multiple file names as input, so we can use the *.fastq wildcard to run FastQC on all of the FASTQ files in this directory.

```bash
$ cloud/project/lewis_and_clark_mini_workshop/unix_tutorial/software/FastQC/fastqc *.fastq
```


The FastQC program has created several new files within our `/data/untrimmed_fastq/` directory. 

```bash
$ ls
```

```
SRR097977.fastq      
SRR097977_fastqc.html
SRR097977_fastqc.zip 
SRR098026.fastq      
SRR098026_fastqc.html
SRR098026_fastqc.zip 
```


For each input FASTQ file, FastQC has created a `.zip` file and a `.html` file. The `.zip` file extension indicates that this is  actually a compressed set of multiple output files. We'll be working with these output files soon. The `.html` file is a stable webpage displaying the summary report for each of our samples.

We want to keep our data files and our results files separate, so we will move these output files into a new directory within a new `results/` directory.

```bash
mkdir cloud/project/lewis_and_clark_mini_workshop/unix_tutorial/results
$ mkdir cloud/project/lewis_and_clark_mini_workshop/unix_tutorial/results/fastqc_untrimmed_reads
$ mv *.zip cloud/project/lewis_and_clark_mini_workshop/unix_tutorial/results/fastqc_untrimmed_reads/
$ mv *.html cloud/project/lewis_and_clark_mini_workshop/unix_tutorial/results/fastqc_untrimmed_reads/
```

Now we can navigate into this results directory and do some closer inspection of our output files.

```bash
$ cd cloud/project/lewis_and_clark_mini_workshop/unix_tutorial/results/fastqc_untrimmed_reads/
```



### Unzipping Compressed Files

Let's look more closely at the other output files. Just to make sure we are in the right deirectory, change to the results sub-directory.

```bash
$ cd cloud/project/lewis_and_clark_mini_workshop/unix_tutorial/results/fastqc_untrimmed_reads/
$ ls
```


```
SRR097977_fastqc.html
SRR097977_fastqc.zip 
SRR098026_fastqc.html
SRR098026_fastqc.zip 
```


Our `.zip` files are compressed files. They each contain multiple different types of output files for a single input FASTQ file. To view the contents of a `.zip` file, we can use the program `unzip`  to decompress these files. Let's unzip both of them with one command.

```bash
$ unzip '*.zip'
```

You should see output that starts like this:

```
Archive:  SRR097977_fastqc.zip
creating: SRR097977_fastqc/
creating: SRR097977_fastqc/Icons/
creating: SRR097977_fastqc/Images/
inflating: SRR097977_fastqc/Icons/fastqc_icon.png  
inflating: SRR097977_fastqc/Icons/warning.png  
inflating: SRR097977_fastqc/Icons/error.png  
inflating: SRR097977_fastqc/Icons/tick.png  
inflating: SRR097977_fastqc/summary.txt  
inflating: SRR097977_fastqc/Images/per_base_quality.png  
inflating: SRR097977_fastqc/Images/per_tile_quality.png  
inflating: SRR097977_fastqc/Images/per_sequence_quality.png  
inflating: SRR097977_fastqc/Images/per_base_sequence_content.png  
inflating: SRR097977_fastqc/Images/per_sequence_gc_content.png  
inflating: SRR097977_fastqc/Images/per_base_n_content.png  
inflating: SRR097977_fastqc/Images/sequence_length_distribution.png  
inflating: SRR097977_fastqc/Images/duplication_levels.png  
inflating: SRR097977_fastqc/Images/adapter_content.png  
inflating: SRR097977_fastqc/Images/kmer_profiles.png  
inflating: SRR097977_fastqc/fastqc_report.html  
inflating: SRR097977_fastqc/fastqc_data.txt  
inflating: SRR097977_fastqc/fastqc.fo  
```


The `unzip` program is decompressing the `.zip` files and creating a new directory (with subdirectories) for each of our samples, to store all of the different output that is produced by FastQC. There are a lot of files here. The one we're going to focus on is the `summary.txt` file. 

### Understanding FastQC Output

If you list the files in our directory now you will see: 

```
SRR097977_fastqc     
SRR097977_fastqc.html
SRR097977_fastqc.zip 
SRR098026_fastqc     
SRR098026_fastqc.html
SRR098026_fastqc.zip 
```

The `.html` files and the uncompressed `.zip` files are still present, but now we also have a new directory for each of our samples. We can see for sure that it's a directory if we use the `-F` flag for `ls`. 

```bash
$ ls -F
```


```
SRR097977_fastqc/    
SRR097977_fastqc.html
SRR097977_fastqc.zip 
SRR098026_fastqc/    
SRR098026_fastqc.html
SRR098026_fastqc.zip 
```

Let's see what files are present within one of these output directories.

```bash
$ ls -F SRR097977_fastqc/
```

```
Icons/	Images/  fastqc.fo  fastqc_data.txt  fastqc_report.html	summary.txt
```


Use `less` to preview the `summary.txt` file for this sample. 

```bash
$ less SRR097977_fastqc/summary.txt
```

```
PASS    Basic Statistics        SRR097977.fastq
WARN    Per base sequence quality       SRR097977.fastq
FAIL    Per tile sequence quality       SRR097977.fastq
PASS    Per sequence quality scores     SRR097977.fastq
PASS    Per base sequence content       SRR097977.fastq
PASS    Per sequence GC content SRR097977.fastq
PASS    Per base N content      SRR097977.fastq
PASS    Sequence Length Distribution    SRR097977.fastq
PASS    Sequence Duplication Levels     SRR097977.fastq
PASS    Overrepresented sequences       SRR097977.fastq
PASS    Adapter Content SRR097977.fastq
WARN    Kmer Content    SRR097977.fastq
```


The summary file gives us a list of tests that FastQC ran, and tells us whether this sample passed, failed, or is borderline (`WARN`).

# Future steps

At this point, we'd continue with the workflow.

![](./media/variant_calling_workflow.png)

# Acknowledgements

This tutorial was adapted from the Data Carpentries genomics Workshop.
